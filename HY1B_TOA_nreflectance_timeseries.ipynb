{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取HY文件星下点数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "def read_HY1B_nadir(file):\n",
    "    try:\n",
    "        f = h5py.File(file, 'r')\n",
    "        \n",
    "        lat = np.array(f['Navigation Data/Latitude'][:,:])\n",
    "        lon = np.array(f['Navigation Data/Longitude'][:,:])\n",
    "        vza = np.array(f['Navigation Data/Satellite Zenith Angle'][:,:])\n",
    "        vaa = np.array(f['Navigation Data/Satellite Azimuth Angle'][:,:])\n",
    "        sza = np.array(f['Navigation Data/Solar Zenith Angle'][:,:])\n",
    "        saa = np.array(f['Navigation Data/Solar Azimuth Angle'][:,:])\n",
    "        \n",
    "        \n",
    "        out = os.path.basename(file)[17:25]\n",
    "        # 宽范围搜索\n",
    "        location = np.where((110<=lon)&(lon<=119)&(lat>=13)&(lat<=18)&(vza<=15))\n",
    "        nir=(np.array(f['Geophysical Data/DN_865'][:,:]))[location]\n",
    "        b = nir>600\n",
    "        nir = nir*1.0\n",
    "        nir[b] = np.nan\n",
    "        mask = nir/nir\n",
    "        \n",
    "        lon = lon[location]*mask\n",
    "        lat = lat[location]*mask\n",
    "        vza = vza[location]*mask\n",
    "        vaa = vaa[location]*mask\n",
    "        sza = sza[location]*mask\n",
    "        saa = saa[location]*mask\n",
    "        \n",
    "        lon = lon.flatten()\n",
    "        lat = lat.flatten()\n",
    "        vza = vza.flatten()\n",
    "        vaa = vaa.flatten()\n",
    "        sza = sza.flatten()\n",
    "        saa = saa.flatten()\n",
    "        \n",
    "        data = {'lat':lat,\n",
    "                'lon':lon,\n",
    "                'vza':vza,\n",
    "                'vaa':vaa,\n",
    "                'sza':sza,\n",
    "                'saa':saa\n",
    "                }\n",
    "        df = pd.DataFrame(data)\n",
    "        gain = np.array(f['Calibration/Calibration Coefficients Scale factor'][:,:]).flatten()\n",
    "        offset = np.array(f['Calibration/Calibration Coefficients Offsets factor'][:,:]).flatten()\n",
    "        calibration_para={\n",
    "        'calibration_coefficients_offset_factors': offset,\n",
    "        'calibration_coefficients_scale_factors': gain,\n",
    "        'time_dependent_correction_constant_terms': np.array(f['Calibration/Time-dependent Correction Constant Terms'][:,:]).flatten(),\n",
    "        'time_dependent_correction_linear_coeficients': np.array(f['Calibration/Time-dependent Correction Linear Coefficients'][:,:]).flatten()\n",
    "        }\n",
    "        df_para = pd.DataFrame(calibration_para)\n",
    "        \n",
    "        bands = ['DN_412', 'DN_443', 'DN_490','DN_520','DN_565','DN_670','DN_750','DN_865']\n",
    "        F0=[173.3835517,191.1745851,197.7310605,183.4959944,180.4321056,149.6390249,126.7797883,95.01985516]\n",
    "        sza2 = np.array(f['Navigation Data/Solar Zenith Angle'][:,:])[location]*mask\n",
    "        \n",
    "        for i,band in enumerate(bands):\n",
    "            radiance = (np.array(f['Geophysical Data/'+band][:,:]))[location]*mask*gain[i]+offset[i]\n",
    "            nr = np.pi*radiance/F0[i]/np.cos(sza2*np.pi/180)\n",
    "            nr = nr.flatten()\n",
    "            band = 'b'+band[3:]\n",
    "            df[band] = nr\n",
    "            mean = np.nanmean(nr)  \n",
    "            median = np.nanmedian(nr)  \n",
    "            std = np.nanstd(nr)  \n",
    "            # ptp = np.ptp(radiance[np.where(radiance < 500)])  # 最大最小值之差\n",
    "            out=out+';'+str(mean)+','+str(median)+','+str(std)  #+','+str(ptp)\n",
    "    except:\n",
    "        out ='error'\n",
    "        data = {'lat':[999],\n",
    "                'lon':[999],\n",
    "                'vza':[999],\n",
    "                'vaa':[999],\n",
    "                'sza':[999],\n",
    "                'saa':[999]\n",
    "                }\n",
    "        df = pd.DataFrame(data)\n",
    "        calibration_para={\n",
    "        'calibration_coefficients_offset_factors': [999],\n",
    "        'calibration_coefficients_scale_factors':[999],\n",
    "        'time_dependent_correction_constant_terms':[999],\n",
    "        'time_dependent_correction_linear_coeficients':[999]\n",
    "         }\n",
    "        df_para = pd.DataFrame(calibration_para)\n",
    "    return out,df,df_para\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 输入的书为HY1B L1A级\n",
    "    filedir=r'G:\\hyProject'\n",
    "    files = glob.glob(filedir+os.sep+'H1B***H5')\n",
    "    text = filedir+os.sep+'HY1B_nReflectanceTerm_.txt.txt'\n",
    "    txt = open(text, 'w')  \n",
    "    pbar = tqdm(total=len(files), desc='processing:')\n",
    "    for i, file in enumerate(files):\n",
    "        LT,df,df_para = read_HY1B_nadir(file)\n",
    "        df.to_csv(path_or_buf=os.path.dirname(file)+os.sep+os.path.basename(file)[0:-3]+'_pixel_level_info.csv', index=False) # 写入csv文件\n",
    "        df_para.to_csv(path_or_buf=os.path.dirname(file)+os.sep+os.path.basename(file)[0:-3]+'_calibration_parameters.csv', index=False) \n",
    "        txt.writelines(LT + '\\n')\n",
    "        if LT =='error':\n",
    "            print('reading file: error')\n",
    "        pbar.update(1)\n",
    "    txt.close()\n",
    "    pbar.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
